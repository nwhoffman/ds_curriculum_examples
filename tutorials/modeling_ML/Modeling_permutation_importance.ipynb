{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In many of the models we've fit, we've looked at the feature importance. This has been accomplished by simply ranking the features after fitting the model. In addition to these basic methods, we can also look at what happens when we change a specific feature. This is called the *permutation importance*.\n",
    "\n",
    "The permute something means to change the order. When we fit a model, we measure the accuracy by comparing our model predictions to the test or validation data. We can test the importance of a feature by permuting the values and then calculating the accuracy against the test set.\n",
    "\n",
    "The process works something like this:\n",
    "\n",
    "* Fit a model and calculate the accuracy\n",
    "* Choose a feature (by ranking the importances or some other method) and randomly permute the values for just that feature\n",
    "* Calculate the accuracy again with the permuted column\n",
    "* Results in a decrease in accuracy: that feature is important to the model\n",
    "* Results in an accuracy that stays the same: the feature isn't important to the model and could be replaced by random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along\n",
    "\n",
    "We'll use the Australian weather data set from the previous module and permute or randomize a few of the features in the test set. The accuracy should change, or decrease, for features that are important to the model. And the accuracy should remain essentially the same for features that are not very important to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries, load data, and view\n",
    "import pandas as pd\n",
    "weather = pd.read_csv('weatherAUS.csv')\n",
    "\n",
    "# Drop columns with high-percentage of missing values (and the leaky feature)\n",
    "cols_drop = ['Location', 'Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm', 'RISK_MM']\n",
    "weather_drop = weather.drop(cols_drop, axis=1)\n",
    "\n",
    "# Convert the 'Date' column to datetime, extract month\n",
    "weather_drop['Date'] = pd.to_datetime(weather_drop['Date'], infer_datetime_format=True).dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline\n",
    "\n",
    "Here we're going to create the preprocessing and model fitting pipeline from the first module in this sprint, so you have seen this code before! Once the model is fit, we can demonstrate the feature-permutation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Define the numeric features\n",
    "numeric_features = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', \n",
    "                    'WindSpeed9am','WindSpeed3pm', 'Humidity9am', \n",
    "                    'Humidity3pm', 'Pressure9am','Pressure3pm', \n",
    "                    'Temp9am', 'Temp3pm']\n",
    "\n",
    "# Create the transformer (impute, scale)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define the categorical features\n",
    "categorical_features = ['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('ordinal', OrdinalEncoder())])\n",
    "\n",
    "# Define how the numeric and categorical features will be transformed\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Define the pipeline steps, including the classifier\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                  ('classifier', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.7793522979007701\n"
     ]
    }
   ],
   "source": [
    "# Create the feature matrix \n",
    "X = weather_drop.drop('RainTomorrow', axis=1)\n",
    "\n",
    "# Create and encode the target array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_enc = LabelEncoder()\n",
    "y=label_enc.fit_transform(weather_drop['RainTomorrow'])\n",
    "\n",
    "# Import the train_test_split utility\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train,y_train)\n",
    "print('Validation Accuracy', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances\n",
    "\n",
    "We're looking at the feature importances now (after removing the problem leaky feature). This is importance because we need to see how the features rank before we change them around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Features (order in which they were preprocessed)\n",
    "features_order = numeric_features + categorical_features\n",
    "\n",
    "importances = pd.Series(clf.steps[1][1].feature_importances_, features_order)\n",
    "\n",
    "# Plot feature importances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(10,n/2))\n",
    "plt.title(f'Top {n} features')\n",
    "importances.sort_values()[-n:].plot.barh(color='grey')\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mod3_obj1_features.png](https://raw.githubusercontent.com/LambdaSchool/data-science-canvas-images/main/unit_2/sprint_3/mod3_obj1_features.png)\n",
    "\n",
    "We can now try a few of the columns and see how permutation of their values affects the accuracy. We'll start with the most important feature (`Humidity3pm`) and then do the same with one of the less important features (`WindSpeed3pm`).\n",
    "\n",
    "We do need to remember to preprocess the permuted data in the same way we did inside of the pipeline above. For the numeric features, we used the `SimpleImputer()` and the `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature permuted:  Humidity3pm\n",
      "Validation Accuracy 0.7793522979007701\n",
      "Validation Accuracy (permuted) 0.699075213615106\n"
     ]
    }
   ],
   "source": [
    "# Permute the values in the more important column\n",
    "feature = 'Humidity3pm'\n",
    "X_test_permuted = X_test.copy()\n",
    "\n",
    "# Fill in missing values\n",
    "X_test_permuted[feature].fillna(value = X_test_permuted[feature].median(), inplace=True)\n",
    "\n",
    "# Permute\n",
    "X_test_permuted[feature] = np.random.permutation(X_test[feature])\n",
    "\n",
    "print('Feature permuted: ', feature)\n",
    "print('Validation Accuracy', clf.score(X_test, y_test))\n",
    "print('Validation Accuracy (permuted)', clf.score(X_test_permuted, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy went down, as we would expect if this feature was important to the model. So `Humidity3pm` has some affect on the model. Let's try another feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature permuted:  WindSpeed3pm\n",
      "Validation Accuracy 0.7793522979007701\n",
      "Validation Accuracy (permuted) 0.7672913956186926\n"
     ]
    }
   ],
   "source": [
    "# Permute the values in a less important column\n",
    "feature = 'WindSpeed3pm'\n",
    "X_test_permuted = X_test.copy()\n",
    "\n",
    "# Fill in missing values\n",
    "X_test_permuted[feature].fillna(value = X_test_permuted[feature].median(), inplace=True)\n",
    "\n",
    "# Permute\n",
    "X_test_permuted[feature] = np.random.permutation(X_test[feature])\n",
    "\n",
    "print('Feature permuted: ', feature)\n",
    "print('Validation Accuracy', clf.score(X_test, y_test))\n",
    "print('Validation Accuracy (permuted)', clf.score(X_test_permuted, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decrease in accuracy was not nearly as significant, so `WindSpeed3pm` is not as important to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Using the above code (you'll need to download the data set from the link below), try permuting other features. We only showed the top 10 features; there are others with even lower feature importance which would be good to try the permutation process with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "* [Kaggle: Permutation Importance](https://www.kaggle.com/dansbecker/permutation-importance)\n",
    "* [Kaggle: Australian Weather Data](https://www.kaggle.com/jsphyg/weather-dataset-rattle-package)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
