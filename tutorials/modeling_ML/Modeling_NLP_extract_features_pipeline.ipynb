{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In Unit 2, we worked with pipelines a lot. We used them to create a consistent work flow of preprocessing and model fitting steps. When we want to use any type of cross-validation, a pipeline was also necessary to ensure that the data was processed in the same way during each fold of the cross-validation.\n",
    "\n",
    "To start off this module, we're going to focus on two tasks: extracting features from text and then classify the text with a simple logistic regression. We'll put these two tasks together in a pipeline and then make use of a grid search cross-validation to find the ideal parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along\n",
    "\n",
    "For this example, we'll be using the sentiment labeled reviews from this [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences). To make this exercise a little simpler and the dataset a little smaller, we'll just use the reviews from Yelp.\n",
    "\n",
    "First, let's vectorize the text data and then fit a classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the locally saved file from the link above\n",
    "df_yelp = pd.read_csv('yelp_labelled.txt', names=['sentence', 'label'], sep='\\t')\n",
    "df_yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the feature and target variables\n",
    "sentences = df_yelp['sentence']\n",
    "y = df_yelp['label']\n",
    "\n",
    "# Train-test split\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "    sentences, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list list of sentences; we did the train-test split before we vectorize. If we instead vectorized the whole training set and then split into train-test sets, the training set would have information about what is in the testing test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<750x2864 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3051 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the tf-idf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate and fit the tf-idf vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range = (2,2))\n",
    "vectorizer.fit(sentences_train)\n",
    "\n",
    "# Vectorize the training and testing data\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)\n",
    "\n",
    "# Display the properties of the vectorized text\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.588\n"
     ]
    }
   ],
   "source": [
    "# Import the classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate and fit a model\n",
    "classifier = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decent accuracy with a logistic regression model. Now, if we want to optimize our model and use cross-validation, we'll need to put the vectorizer and classifier steps in each fold of the cross-validation. As we learned in Unit 2, we need to apply the same transformation within each fold of the validation, otherwise we could accidentally introduce data leakage (where we give the model more information about the data that it shouldn't have).\n",
    "\n",
    "Our pipeline will have two steps: the vectorizer and the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    2.3s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.611"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([('vect', vectorizer), # vectorizer\n",
    "                 ('clf', classifier) # classifier\n",
    "                ])\n",
    "\n",
    "# Define the parameter space for the grid serach\n",
    "parameters = {'clf__C': [1, 10, 1000000]} # C: regularization strength\n",
    "\n",
    "\n",
    "# Implement a grid search with cross-validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(sentences, y);\n",
    "\n",
    "# Print out the best score\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is improved compared to the version we did without a grid search. It's relatively straightforward to adjust the parameters that you would like to perform the grid search over. In this case, the only somewhat useful parameter to search over is the C or the inverse of the regularization. For classifiers with more parameters, you just add a key:value pair to the `parameters` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "For this challenge, try using a different classifier in place of the logistic regression. Make sure to adjust the `parameters` dictionary to be consistent with the classifier you choose. Some suggested classifiers to begin with are a decision tree or a random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "* [Scikit-learn: Logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "* [Scikit-learn: Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "* [UCI: Sentiment Labelled Sentences](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
